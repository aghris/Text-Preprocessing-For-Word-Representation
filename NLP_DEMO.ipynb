{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_DEMO.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beXl8OeN4oEY"
      },
      "source": [
        "#  <h1><center>A Comprehensive Analysis of Preprocessing for Word Representation Learning in Affective Tasks Implementation</center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j26fdhzl443X"
      },
      "source": [
        "In this work, we implement four text processing techniques namely, stopword removal, Stemming and Post tagg then, we apply it to the training corpus before the models start to learn the word embedding. In first place, we perform each tool individually to evaluate its effect on the performance results then, in second place we use all the processing factors together. On other hand, we incorporate only basic processing into the text used as input for the classification.\n",
        "Implementing negation and Spellercheck techniques requires constracting the antonym dictionary and the customized dictionary of correction, which takes to much time. We will not implement them, but since we are working on an affective task we remove negation expression from stop word list such as 'no', 'never', 'neither'...\n",
        "Due to the performance limit of our machines we used only two word embedding models: CBOW and Skip-gram. For the training corpus, we took only one third of the News articles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNCBYdijbj9V"
      },
      "source": [
        "# Import Librairies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSOJVahF1xQM"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from keras.layers import Input, Embedding, LSTM, Dense\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import gc\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from gensim.models import Word2Vec\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import load_model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubpe3p8abqOI"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StecRdK0-J6u"
      },
      "source": [
        "def embeddings(path):\n",
        "  embeddings_dictionary = dict()\n",
        "  glove_file = open(path, encoding=\"utf8\")\n",
        "\n",
        "  for line in glove_file:\n",
        "      records = line.split()\n",
        "      word = records[0]\n",
        "      vector_dimensions = asarray(records[1:])\n",
        "      embeddings_dictionary [word] = vector_dimensions\n",
        "  glove_file.close()\n",
        "  embedding_matrix = zeros((vocab_size, 300))\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "      embedding_vector = embeddings_dictionary.get(word)\n",
        "      if embedding_vector is not None:\n",
        "          embedding_matrix[index] = embedding_vector\n",
        "  return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBVUJdrFHx5U"
      },
      "source": [
        "def get_model(X_train, y_train, embedding_matrix, name):\n",
        "  model = Sequential()\n",
        "  embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "  model.add(embedding_layer)\n",
        "  model.add(LSTM(128))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "  path = \"../Weights/\"+name+\".h5\"\n",
        "  mc = ModelCheckpoint(path, monitor='val_acc',\n",
        "                       mode='max', verbose=1, save_best_only=True)\n",
        "\t# fit model\n",
        "  model.fit(X_train, y_train, batch_size=128, epochs=10000, verbose=1, validation_split=0.10, callbacks=[es, mc])\n",
        "  return model, path\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wepXyPFjVaZ3"
      },
      "source": [
        "def eval_model(path):\n",
        "  saved_model =  load_model(path)\n",
        "  yhat_probs = saved_model.predict(X_test, verbose=1)\n",
        "  # predict crisp classes for test set\n",
        "  yhat_classes = saved_model.predict_classes(X_test, verbose=1)\n",
        "  # reduce to 1d array\n",
        "  yhat_probs = yhat_probs[:, 0]\n",
        "  yhat_classes = yhat_classes[:, 0]\n",
        "  \n",
        "  # accuracy: (tp + tn) / (p + n)\n",
        "  accuracy = accuracy_score(y_test, yhat_classes)\n",
        "  print('Accuracy: %f' % accuracy)\n",
        "  # precision tp / (tp + fp)\n",
        "  precision = precision_score(y_test, yhat_classes)\n",
        "  print('Precision: %f' % precision)\n",
        "  # recall: tp / (tp + fn)\n",
        "  recall = recall_score(y_test, yhat_classes)\n",
        "  print('Recall: %f' % recall)\n",
        "  # f1: 2 tp / (2 tp + fp + fn)\n",
        "  f1 = f1_score(y_test, yhat_classes)\n",
        "  print('F1 score: %f' % f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnHzO4Lhbz4s"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1_42CNz26UN"
      },
      "source": [
        "path = \"../data/IMDB Dataset.csv\"\n",
        "movie_reviews = pd.read_csv(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "MGJb-UR22_n9",
        "outputId": "061c920b-d140-410a-d5a9-a2cb2f7aa780"
      },
      "source": [
        "movie_reviews.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA-9ydrp3BvD",
        "outputId": "2eccb2f8-be2b-4c77-ee34-775e959c8b60"
      },
      "source": [
        "movie_reviews.sentiment.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    25000\n",
              "negative    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYZv8BML3FNr"
      },
      "source": [
        "text= movie_reviews['review']\n",
        "X=text.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvDsreUc3UGw"
      },
      "source": [
        "def majid(X):\n",
        "    corpus = []\n",
        "    for i in range(0, len(X)):\n",
        "        #review = re.sub(r'[@%\\\\*=()/~#&\\+รก?\\xc3\\xa1\\-\\|\\.\\:\\;\\!\\-\\,\\_\\~\\$\\'\\\"]', '',str(X[i])) #remove punctuation\n",
        "        review = re.sub(r'\\d+',' ', str(X[i]))# remove number\n",
        "        review = review.lower() #lower case\n",
        "        review = re.sub(r'\\s+', ' ', review) #remove extra space\n",
        "        review = re.sub(r'<[^>]+>','',review) #remove Html tags\n",
        "        review = re.sub(r'\\s+', ' ', review) #remove spaces\n",
        "        review = re.sub(r\"^\\s+\", '', review) #remove space from start\n",
        "        review = re.sub(r'\\s+$', '', review) #remove space from the end\n",
        "        corpus.append(review)        \n",
        "#    return corpus        \n",
        "    #Tokenizing and Word Count  \n",
        "    words=[]\n",
        "    for i in range(len(corpus)):\n",
        "        words= nltk.word_tokenize(corpus[i])\n",
        "        #sentences.append(words)\n",
        "   \n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QILXSXv23aF9"
      },
      "source": [
        "X = [[el] for el in X] \n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF4Ms5ku3gJ7",
        "outputId": "f1711d4b-551f-4245-cb6c-d55114ffa38c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCff59bq3bmP"
      },
      "source": [
        "num_cores = multiprocessing.cpu_count()\n",
        "sentences = Parallel(n_jobs=num_cores)(delayed(majid)(i) for i in X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D-bh1Cm4IK9"
      },
      "source": [
        "X = [' '.join(x) for x in sentences]\n",
        "y = movie_reviews['sentiment']\n",
        "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgaWbmq29v7U",
        "outputId": "536a2a72-c4e6-4b32-f3e7-d9eacf03a7f3"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "# Adding 1 because of reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocab size:',vocab_size)\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 98434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UImV00LWKfHU"
      },
      "source": [
        "# Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQcsT5dieI4m"
      },
      "source": [
        "# Embeddings path\n",
        "path_emb = \"../Embeddings/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOoMI0ieH44Y",
        "outputId": "7d0041cd-f5e0-4262-de0a-88c7626448f5"
      },
      "source": [
        "embedding_matrix = embeddings(path_emb + \"W-Skip-Stem.txt\")\n",
        "model, path = get_model(X_train, y_train, embedding_matrix, path.split(\"/\")[-1].split(\".\")[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "282/282 [==============================] - 6s 17ms/step - loss: 0.6481 - acc: 0.6044 - val_loss: 0.5429 - val_acc: 0.7230\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.72300, saving model to /content/drive/MyDrive/NLP/W-Skip-Stem.h5\n",
            "Epoch 2/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.5155 - acc: 0.7458 - val_loss: 0.4757 - val_acc: 0.7720\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.72300 to 0.77200, saving model to /content/drive/MyDrive/NLP/W-Skip-Stem.h5\n",
            "Epoch 3/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4725 - acc: 0.7769 - val_loss: 0.4652 - val_acc: 0.7720\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.77200\n",
            "Epoch 4/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4470 - acc: 0.7933 - val_loss: 0.4611 - val_acc: 0.7828\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.77200 to 0.78275, saving model to /content/drive/MyDrive/NLP/W-Skip-Stem.h5\n",
            "Epoch 5/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4170 - acc: 0.8073 - val_loss: 0.4164 - val_acc: 0.8035\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.78275 to 0.80350, saving model to /content/drive/MyDrive/NLP/W-Skip-Stem.h5\n",
            "Epoch 6/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3914 - acc: 0.8228 - val_loss: 0.4243 - val_acc: 0.8033\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80350\n",
            "Epoch 7/10000\n",
            "282/282 [==============================] - 4s 16ms/step - loss: 0.3701 - acc: 0.8349 - val_loss: 0.4245 - val_acc: 0.8020\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80350\n",
            "Epoch 8/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3446 - acc: 0.8489 - val_loss: 0.4127 - val_acc: 0.8115\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.80350 to 0.81150, saving model to /content/drive/MyDrive/NLP/W-Skip-Stem.h5\n",
            "Epoch 9/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3257 - acc: 0.8577 - val_loss: 0.4148 - val_acc: 0.8130\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.81150 to 0.81300, saving model to /content/drive/MyDrive/NLP/W-Skip-Stem.h5\n",
            "Epoch 10/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2846 - acc: 0.8760 - val_loss: 0.4177 - val_acc: 0.8087\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.81300\n",
            "Epoch 11/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2679 - acc: 0.8873 - val_loss: 0.4355 - val_acc: 0.8140\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.81300 to 0.81400, saving model to /content/drive/MyDrive/NLP/W-Skip-Stem.h5\n",
            "Epoch 12/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2304 - acc: 0.9056 - val_loss: 0.4511 - val_acc: 0.8073\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.81400\n",
            "Epoch 13/10000\n",
            "282/282 [==============================] - 4s 16ms/step - loss: 0.1989 - acc: 0.9207 - val_loss: 0.4821 - val_acc: 0.8077\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.81400\n",
            "Epoch 14/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1689 - acc: 0.9344 - val_loss: 0.5316 - val_acc: 0.8083\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.81400\n",
            "Epoch 15/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1362 - acc: 0.9500 - val_loss: 0.6391 - val_acc: 0.8005\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.81400\n",
            "Epoch 16/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1204 - acc: 0.9569 - val_loss: 0.6108 - val_acc: 0.8033\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.81400\n",
            "Epoch 17/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0929 - acc: 0.9689 - val_loss: 0.7219 - val_acc: 0.7987\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.81400\n",
            "Epoch 18/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0804 - acc: 0.9734 - val_loss: 0.7881 - val_acc: 0.7997\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.81400\n",
            "Epoch 00018: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJNCQ1cQQIbX",
        "outputId": "0b77e077-13b6-4903-aa5a-e620b57f081d"
      },
      "source": [
        "eval_model(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            " 39/313 [==>...........................] - ETA: 1s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.821800\n",
            "Precision: 0.816152\n",
            "Recall: 0.834293\n",
            "F1 score: 0.825123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRxYYwWWQrmg",
        "outputId": "95d6b272-2be2-49c4-cce0-87c4e916da28"
      },
      "source": [
        "embedding_matrix = embeddings(path_emb + \"W-CBOW-Stem.txt\")\n",
        "model, path = get_model(X_train, y_train, embedding_matrix, path.split(\"/\")[-1].split(\".\")[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "282/282 [==============================] - 6s 17ms/step - loss: 0.6159 - acc: 0.6482 - val_loss: 0.5126 - val_acc: 0.7577\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.75775, saving model to /content/drive/MyDrive/NLP/W-CBOW-Stem.h5\n",
            "Epoch 2/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4828 - acc: 0.7701 - val_loss: 0.4771 - val_acc: 0.7740\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.75775 to 0.77400, saving model to /content/drive/MyDrive/NLP/W-CBOW-Stem.h5\n",
            "Epoch 3/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4391 - acc: 0.7941 - val_loss: 0.4441 - val_acc: 0.7983\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.77400 to 0.79825, saving model to /content/drive/MyDrive/NLP/W-CBOW-Stem.h5\n",
            "Epoch 4/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4094 - acc: 0.8150 - val_loss: 0.4569 - val_acc: 0.7975\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.79825\n",
            "Epoch 5/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3759 - acc: 0.8308 - val_loss: 0.4133 - val_acc: 0.8163\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.79825 to 0.81625, saving model to /content/drive/MyDrive/NLP/W-CBOW-Stem.h5\n",
            "Epoch 6/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3443 - acc: 0.8498 - val_loss: 0.4038 - val_acc: 0.8165\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.81625 to 0.81650, saving model to /content/drive/MyDrive/NLP/W-CBOW-Stem.h5\n",
            "Epoch 7/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3042 - acc: 0.8700 - val_loss: 0.4142 - val_acc: 0.8155\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.81650\n",
            "Epoch 8/10000\n",
            "282/282 [==============================] - 4s 16ms/step - loss: 0.2840 - acc: 0.8805 - val_loss: 0.4464 - val_acc: 0.7968\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.81650\n",
            "Epoch 9/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2507 - acc: 0.8975 - val_loss: 0.4399 - val_acc: 0.8135\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.81650\n",
            "Epoch 10/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2175 - acc: 0.9107 - val_loss: 0.4834 - val_acc: 0.8175\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.81650 to 0.81750, saving model to /content/drive/MyDrive/NLP/W-CBOW-Stem.h5\n",
            "Epoch 11/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1781 - acc: 0.9307 - val_loss: 0.4848 - val_acc: 0.8202\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.81750 to 0.82025, saving model to /content/drive/MyDrive/NLP/W-CBOW-Stem.h5\n",
            "Epoch 12/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1424 - acc: 0.9470 - val_loss: 0.6148 - val_acc: 0.8025\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.82025\n",
            "Epoch 13/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1124 - acc: 0.9601 - val_loss: 0.6597 - val_acc: 0.7935\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.82025\n",
            "Epoch 14/10000\n",
            "282/282 [==============================] - 4s 16ms/step - loss: 0.0933 - acc: 0.9666 - val_loss: 0.6426 - val_acc: 0.8125\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.82025\n",
            "Epoch 15/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0734 - acc: 0.9772 - val_loss: 0.7535 - val_acc: 0.8040\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.82025\n",
            "Epoch 16/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0688 - acc: 0.9776 - val_loss: 0.7800 - val_acc: 0.7983\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.82025\n",
            "Epoch 00016: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_S_LUk4W7cn",
        "outputId": "d8d88b11-c726-4474-9762-8e9c85035a66"
      },
      "source": [
        "eval_model(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            " 40/313 [==>...........................] - ETA: 1s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.823000\n",
            "Precision: 0.819301\n",
            "Recall: 0.832308\n",
            "F1 score: 0.825753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrnEZ7bk-nfC"
      },
      "source": [
        "We note ,in the case of applying only stemming, that the embedding generated using CBOW and Skip gram leads almost to the same results in the classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m4N5Z94g1Sq"
      },
      "source": [
        "# Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RvvT1RWg28L",
        "outputId": "7d204027-c03e-41ce-b3a6-1d2d5148b2c3"
      },
      "source": [
        "embedding_matrix = embeddings(path_emb + \"W-Skip-Punc.txt\")\n",
        "model, path = get_model(X_train, y_train, embedding_matrix, path.split(\"/\")[-1].split(\".\")[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "282/282 [==============================] - 6s 17ms/step - loss: 0.6049 - acc: 0.6607 - val_loss: 0.4561 - val_acc: 0.7908\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.79075, saving model to /content/drive/MyDrive/NLP/W-Skip-Punc.h5\n",
            "Epoch 2/10000\n",
            "282/282 [==============================] - 4s 16ms/step - loss: 0.4756 - acc: 0.7754 - val_loss: 0.4424 - val_acc: 0.8033\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.79075 to 0.80325, saving model to /content/drive/MyDrive/NLP/W-Skip-Punc.h5\n",
            "Epoch 3/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4199 - acc: 0.8107 - val_loss: 0.3840 - val_acc: 0.8227\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.80325 to 0.82275, saving model to /content/drive/MyDrive/NLP/W-Skip-Punc.h5\n",
            "Epoch 4/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3789 - acc: 0.8336 - val_loss: 0.3567 - val_acc: 0.8418\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.82275 to 0.84175, saving model to /content/drive/MyDrive/NLP/W-Skip-Punc.h5\n",
            "Epoch 5/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3443 - acc: 0.8478 - val_loss: 0.3545 - val_acc: 0.8400\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.84175\n",
            "Epoch 6/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3243 - acc: 0.8595 - val_loss: 0.3573 - val_acc: 0.8388\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.84175\n",
            "Epoch 7/10000\n",
            "282/282 [==============================] - 5s 16ms/step - loss: 0.2999 - acc: 0.8730 - val_loss: 0.3377 - val_acc: 0.8558\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.84175 to 0.85575, saving model to /content/drive/MyDrive/NLP/W-Skip-Punc.h5\n",
            "Epoch 8/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2817 - acc: 0.8814 - val_loss: 0.3461 - val_acc: 0.8595\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.85575 to 0.85950, saving model to /content/drive/MyDrive/NLP/W-Skip-Punc.h5\n",
            "Epoch 9/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2444 - acc: 0.8986 - val_loss: 0.3490 - val_acc: 0.8547\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.85950\n",
            "Epoch 10/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2208 - acc: 0.9108 - val_loss: 0.3598 - val_acc: 0.8508\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.85950\n",
            "Epoch 11/10000\n",
            "282/282 [==============================] - 5s 16ms/step - loss: 0.1952 - acc: 0.9227 - val_loss: 0.3651 - val_acc: 0.8470\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.85950\n",
            "Epoch 12/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1558 - acc: 0.9401 - val_loss: 0.4157 - val_acc: 0.8482\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.85950\n",
            "Epoch 13/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1331 - acc: 0.9490 - val_loss: 0.4450 - val_acc: 0.8447\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.85950\n",
            "Epoch 14/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1078 - acc: 0.9608 - val_loss: 0.4529 - val_acc: 0.8440\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.85950\n",
            "Epoch 15/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0833 - acc: 0.9718 - val_loss: 0.5540 - val_acc: 0.8405\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.85950\n",
            "Epoch 16/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0573 - acc: 0.9838 - val_loss: 0.5720 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.85950\n",
            "Epoch 17/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0575 - acc: 0.9806 - val_loss: 0.5867 - val_acc: 0.8443\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.85950\n",
            "Epoch 00017: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHM1c_tThDP0",
        "outputId": "f1f729b3-e4c4-407a-e78a-e719ade26dd4"
      },
      "source": [
        "eval_model(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            " 37/313 [==>...........................] - ETA: 1s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.862900\n",
            "Precision: 0.844090\n",
            "Recall: 0.892836\n",
            "F1 score: 0.867779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw2t_cE9hKJS",
        "outputId": "a48b7e31-31f6-4c12-b348-595e8e7d4c84"
      },
      "source": [
        "embedding_matrix = embeddings(path_emb + \"W-CBOW-Punc.txt\")\n",
        "model, path = get_model(X_train, y_train, embedding_matrix, path.split(\"/\")[-1].split(\".\")[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "282/282 [==============================] - 7s 17ms/step - loss: 0.5924 - acc: 0.6671 - val_loss: 0.4615 - val_acc: 0.7860\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78600, saving model to /content/drive/MyDrive/NLP/W-CBOW-Punc.h5\n",
            "Epoch 2/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4548 - acc: 0.7909 - val_loss: 0.3998 - val_acc: 0.8145\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.78600 to 0.81450, saving model to /content/drive/MyDrive/NLP/W-CBOW-Punc.h5\n",
            "Epoch 3/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3935 - acc: 0.8221 - val_loss: 0.3755 - val_acc: 0.8295\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.81450 to 0.82950, saving model to /content/drive/MyDrive/NLP/W-CBOW-Punc.h5\n",
            "Epoch 4/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3473 - acc: 0.8482 - val_loss: 0.4077 - val_acc: 0.8112\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.82950\n",
            "Epoch 5/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3122 - acc: 0.8655 - val_loss: 0.3453 - val_acc: 0.8508\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.82950 to 0.85075, saving model to /content/drive/MyDrive/NLP/W-CBOW-Punc.h5\n",
            "Epoch 6/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2732 - acc: 0.8847 - val_loss: 0.3651 - val_acc: 0.8460\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.85075\n",
            "Epoch 7/10000\n",
            "282/282 [==============================] - 5s 16ms/step - loss: 0.2281 - acc: 0.9074 - val_loss: 0.3696 - val_acc: 0.8418\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.85075\n",
            "Epoch 8/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2000 - acc: 0.9193 - val_loss: 0.4161 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.85075 to 0.85375, saving model to /content/drive/MyDrive/NLP/W-CBOW-Punc.h5\n",
            "Epoch 9/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1601 - acc: 0.9379 - val_loss: 0.4092 - val_acc: 0.8367\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.85375\n",
            "Epoch 10/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1202 - acc: 0.9577 - val_loss: 0.4435 - val_acc: 0.8470\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.85375\n",
            "Epoch 11/10000\n",
            "282/282 [==============================] - 5s 16ms/step - loss: 0.1020 - acc: 0.9650 - val_loss: 0.4612 - val_acc: 0.8530\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.85375\n",
            "Epoch 12/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0665 - acc: 0.9789 - val_loss: 0.5437 - val_acc: 0.8400\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.85375\n",
            "Epoch 13/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0448 - acc: 0.9879 - val_loss: 0.6515 - val_acc: 0.8265\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.85375\n",
            "Epoch 14/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0523 - acc: 0.9843 - val_loss: 0.6061 - val_acc: 0.8443\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.85375\n",
            "Epoch 15/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0295 - acc: 0.9926 - val_loss: 0.6374 - val_acc: 0.8382\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.85375\n",
            "Epoch 00015: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtAXyJRthOzU",
        "outputId": "7f9c18f2-3ba7-44dd-e782-5ec5f81e378e"
      },
      "source": [
        "eval_model(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            " 40/313 [==>...........................] - ETA: 1s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.851500\n",
            "Precision: 0.835157\n",
            "Recall: 0.878746\n",
            "F1 score: 0.856397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU19jYV6_bUx"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nznk5ffjktZW"
      },
      "source": [
        "# Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYMnw-dohPhp",
        "outputId": "0827208c-e3b9-4016-9396-dad161d70daa"
      },
      "source": [
        "embedding_matrix = embeddings(path_emb + \"W-Skip-Stop.txt\")\n",
        "model, path = get_model(X_train, y_train, embedding_matrix, path.split(\"/\")[-1].split(\".\")[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "282/282 [==============================] - 7s 17ms/step - loss: 0.5636 - acc: 0.7016 - val_loss: 0.4457 - val_acc: 0.7903\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.79025, saving model to /content/drive/MyDrive/NLP/W-Skip-Stop.h5\n",
            "Epoch 2/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4508 - acc: 0.7915 - val_loss: 0.4093 - val_acc: 0.8130\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.79025 to 0.81300, saving model to /content/drive/MyDrive/NLP/W-Skip-Stop.h5\n",
            "Epoch 3/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4087 - acc: 0.8167 - val_loss: 0.3964 - val_acc: 0.8125\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.81300\n",
            "Epoch 4/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3909 - acc: 0.8259 - val_loss: 0.4021 - val_acc: 0.8173\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.81300 to 0.81725, saving model to /content/drive/MyDrive/NLP/W-Skip-Stop.h5\n",
            "Epoch 5/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3506 - acc: 0.8472 - val_loss: 0.3760 - val_acc: 0.8230\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.81725 to 0.82300, saving model to /content/drive/MyDrive/NLP/W-Skip-Stop.h5\n",
            "Epoch 6/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3377 - acc: 0.8513 - val_loss: 0.3837 - val_acc: 0.8415\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.82300 to 0.84150, saving model to /content/drive/MyDrive/NLP/W-Skip-Stop.h5\n",
            "Epoch 7/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3141 - acc: 0.8647 - val_loss: 0.3565 - val_acc: 0.8465\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.84150 to 0.84650, saving model to /content/drive/MyDrive/NLP/W-Skip-Stop.h5\n",
            "Epoch 8/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2989 - acc: 0.8760 - val_loss: 0.3592 - val_acc: 0.8405\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.84650\n",
            "Epoch 9/10000\n",
            "282/282 [==============================] - 4s 16ms/step - loss: 0.2856 - acc: 0.8798 - val_loss: 0.4042 - val_acc: 0.8320\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.84650\n",
            "Epoch 10/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2489 - acc: 0.8970 - val_loss: 0.3956 - val_acc: 0.8365\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.84650\n",
            "Epoch 11/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2300 - acc: 0.9073 - val_loss: 0.4039 - val_acc: 0.8363\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.84650\n",
            "Epoch 12/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2107 - acc: 0.9133 - val_loss: 0.4073 - val_acc: 0.8380\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.84650\n",
            "Epoch 13/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1812 - acc: 0.9303 - val_loss: 0.4254 - val_acc: 0.8363\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.84650\n",
            "Epoch 14/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1525 - acc: 0.9430 - val_loss: 0.4430 - val_acc: 0.8260\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.84650\n",
            "Epoch 15/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1282 - acc: 0.9534 - val_loss: 0.5734 - val_acc: 0.8215\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.84650\n",
            "Epoch 16/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1176 - acc: 0.9581 - val_loss: 0.5657 - val_acc: 0.8288\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.84650\n",
            "Epoch 17/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0976 - acc: 0.9645 - val_loss: 0.5803 - val_acc: 0.8355\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.84650\n",
            "Epoch 00017: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_071gcalEKW",
        "outputId": "fd46ee86-0cef-4ace-f4ce-c4c8d7349d2b"
      },
      "source": [
        "eval_model(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            " 40/313 [==>...........................] - ETA: 1s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.842900\n",
            "Precision: 0.846523\n",
            "Recall: 0.840643\n",
            "F1 score: 0.843573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6cMOP46lGxp",
        "outputId": "f2d8c53d-1066-4e78-bd02-1c8512fd65b5"
      },
      "source": [
        "embedding_matrix = embeddings(path_emb + \"W-CBOW-Stop.txt\")\n",
        "model, path = get_model(X_train, y_train, embedding_matrix, path.split(\"/\")[-1].split(\".\")[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "282/282 [==============================] - 7s 17ms/step - loss: 0.5838 - acc: 0.6883 - val_loss: 0.4434 - val_acc: 0.7903\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.79025, saving model to /content/drive/MyDrive/NLP/W-CBOW-Stop.h5\n",
            "Epoch 2/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4446 - acc: 0.7962 - val_loss: 0.4053 - val_acc: 0.8105\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.79025 to 0.81050, saving model to /content/drive/MyDrive/NLP/W-CBOW-Stop.h5\n",
            "Epoch 3/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4019 - acc: 0.8173 - val_loss: 0.3825 - val_acc: 0.8250\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.81050 to 0.82500, saving model to /content/drive/MyDrive/NLP/W-CBOW-Stop.h5\n",
            "Epoch 4/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3639 - acc: 0.8374 - val_loss: 0.3821 - val_acc: 0.8248\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.82500\n",
            "Epoch 5/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3503 - acc: 0.8449 - val_loss: 0.3793 - val_acc: 0.8367\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.82500 to 0.83675, saving model to /content/drive/MyDrive/NLP/W-CBOW-Stop.h5\n",
            "Epoch 6/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3216 - acc: 0.8620 - val_loss: 0.4034 - val_acc: 0.8152\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.83675\n",
            "Epoch 7/10000\n",
            "282/282 [==============================] - 4s 16ms/step - loss: 0.2970 - acc: 0.8729 - val_loss: 0.3753 - val_acc: 0.8345\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.83675\n",
            "Epoch 8/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2659 - acc: 0.8893 - val_loss: 0.3931 - val_acc: 0.8375\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.83675 to 0.83750, saving model to /content/drive/MyDrive/NLP/W-CBOW-Stop.h5\n",
            "Epoch 9/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2401 - acc: 0.9002 - val_loss: 0.3967 - val_acc: 0.8303\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.83750\n",
            "Epoch 10/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2172 - acc: 0.9128 - val_loss: 0.4340 - val_acc: 0.8330\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.83750\n",
            "Epoch 11/10000\n",
            "282/282 [==============================] - 4s 16ms/step - loss: 0.1999 - acc: 0.9196 - val_loss: 0.4565 - val_acc: 0.8260\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.83750\n",
            "Epoch 12/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1602 - acc: 0.9408 - val_loss: 0.4656 - val_acc: 0.8170\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.83750\n",
            "Epoch 13/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1320 - acc: 0.9503 - val_loss: 0.5216 - val_acc: 0.8108\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.83750\n",
            "Epoch 14/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1003 - acc: 0.9661 - val_loss: 0.5758 - val_acc: 0.8210\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.83750\n",
            "Epoch 15/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0913 - acc: 0.9695 - val_loss: 0.6018 - val_acc: 0.8167\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.83750\n",
            "Epoch 16/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0686 - acc: 0.9782 - val_loss: 0.6880 - val_acc: 0.8232\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.83750\n",
            "Epoch 17/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0495 - acc: 0.9858 - val_loss: 0.7234 - val_acc: 0.7993\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.83750\n",
            "Epoch 00017: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FhZiH81lLYR",
        "outputId": "565692f2-38d8-47e0-93d7-81715a8c292d"
      },
      "source": [
        "eval_model(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            " 39/313 [==>...........................] - ETA: 1s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.841000\n",
            "Precision: 0.863282\n",
            "Recall: 0.813257\n",
            "F1 score: 0.837523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7d4AxXw3Hmc"
      },
      "source": [
        "# POS Tagger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IPlbBR6uKfs",
        "outputId": "b755a939-86e3-42ac-97fe-f7c75993d8db"
      },
      "source": [
        "path = \"/content/drive/MyDrive/NLP/W-Skip-POS.txt\"\n",
        "embedding_matrix = embeddings(path_emb + \"W-Skip-POS.txt\")\n",
        "model, path = get_model(X_train, y_train, embedding_matrix, path.split(\"/\")[-1].split(\".\")[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "282/282 [==============================] - 6s 17ms/step - loss: 0.6125 - acc: 0.6432 - val_loss: 0.4463 - val_acc: 0.7878\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78775, saving model to /content/drive/MyDrive/NLP/W-Skip-POS.h5\n",
            "Epoch 2/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4549 - acc: 0.7881 - val_loss: 0.5537 - val_acc: 0.7245\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.78775\n",
            "Epoch 3/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4410 - acc: 0.7942 - val_loss: 0.3825 - val_acc: 0.8248\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.78775 to 0.82475, saving model to /content/drive/MyDrive/NLP/W-Skip-POS.h5\n",
            "Epoch 4/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3735 - acc: 0.8353 - val_loss: 0.4000 - val_acc: 0.8250\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.82475 to 0.82500, saving model to /content/drive/MyDrive/NLP/W-Skip-POS.h5\n",
            "Epoch 5/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3466 - acc: 0.8482 - val_loss: 0.3580 - val_acc: 0.8367\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.82500 to 0.83675, saving model to /content/drive/MyDrive/NLP/W-Skip-POS.h5\n",
            "Epoch 6/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3103 - acc: 0.8664 - val_loss: 0.3824 - val_acc: 0.8238\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.83675\n",
            "Epoch 7/10000\n",
            "282/282 [==============================] - 5s 16ms/step - loss: 0.2916 - acc: 0.8749 - val_loss: 0.3514 - val_acc: 0.8512\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.83675 to 0.85125, saving model to /content/drive/MyDrive/NLP/W-Skip-POS.h5\n",
            "Epoch 8/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2569 - acc: 0.8961 - val_loss: 0.3514 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.85125\n",
            "Epoch 9/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2282 - acc: 0.9060 - val_loss: 0.3716 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.85125 to 0.85225, saving model to /content/drive/MyDrive/NLP/W-Skip-POS.h5\n",
            "Epoch 10/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1925 - acc: 0.9236 - val_loss: 0.3904 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.85225 to 0.85375, saving model to /content/drive/MyDrive/NLP/W-Skip-POS.h5\n",
            "Epoch 11/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1589 - acc: 0.9395 - val_loss: 0.4281 - val_acc: 0.8413\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.85375\n",
            "Epoch 12/10000\n",
            "282/282 [==============================] - 4s 16ms/step - loss: 0.1304 - acc: 0.9514 - val_loss: 0.5050 - val_acc: 0.8238\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.85375\n",
            "Epoch 13/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1151 - acc: 0.9579 - val_loss: 0.4889 - val_acc: 0.8360\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.85375\n",
            "Epoch 14/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0794 - acc: 0.9740 - val_loss: 0.5814 - val_acc: 0.8255\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.85375\n",
            "Epoch 15/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0643 - acc: 0.9791 - val_loss: 0.6182 - val_acc: 0.8320\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.85375\n",
            "Epoch 16/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0492 - acc: 0.9859 - val_loss: 0.6718 - val_acc: 0.8432\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.85375\n",
            "Epoch 17/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0461 - acc: 0.9868 - val_loss: 0.7013 - val_acc: 0.8413\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.85375\n",
            "Epoch 18/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0287 - acc: 0.9929 - val_loss: 0.7460 - val_acc: 0.8465\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.85375\n",
            "Epoch 00018: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZnVzsZp3XTB",
        "outputId": "5da0c607-ee7c-4d86-a457-93accde5daa6"
      },
      "source": [
        "eval_model(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            " 38/313 [==>...........................] - ETA: 1s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.859500\n",
            "Precision: 0.875879\n",
            "Recall: 0.840246\n",
            "F1 score: 0.857693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs7dFZL54AJ7",
        "outputId": "6b4ca97f-e4fe-4a1d-c283-59998c2487f6"
      },
      "source": [
        "embedding_matrix = embeddings(path_emb + \"W-CBOW-POS.txt\")\n",
        "model, path = get_model(X_train, y_train, embedding_matrix, path.split(\"/\")[-1].split(\".\")[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "282/282 [==============================] - 7s 17ms/step - loss: 0.6053 - acc: 0.6530 - val_loss: 0.4571 - val_acc: 0.7883\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78825, saving model to /content/drive/MyDrive/NLP/W-CBOW-POS.h5\n",
            "Epoch 2/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4425 - acc: 0.7956 - val_loss: 0.4018 - val_acc: 0.8130\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.78825 to 0.81300, saving model to /content/drive/MyDrive/NLP/W-CBOW-POS.h5\n",
            "Epoch 3/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3900 - acc: 0.8240 - val_loss: 0.4006 - val_acc: 0.8130\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.81300\n",
            "Epoch 4/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3313 - acc: 0.8554 - val_loss: 0.3588 - val_acc: 0.8482\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.81300 to 0.84825, saving model to /content/drive/MyDrive/NLP/W-CBOW-POS.h5\n",
            "Epoch 5/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3121 - acc: 0.8648 - val_loss: 0.3513 - val_acc: 0.8415\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.84825\n",
            "Epoch 6/10000\n",
            "282/282 [==============================] - 5s 16ms/step - loss: 0.2596 - acc: 0.8938 - val_loss: 0.3521 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.84825 to 0.85025, saving model to /content/drive/MyDrive/NLP/W-CBOW-POS.h5\n",
            "Epoch 7/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2227 - acc: 0.9102 - val_loss: 0.3510 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.85025 to 0.85225, saving model to /content/drive/MyDrive/NLP/W-CBOW-POS.h5\n",
            "Epoch 8/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1797 - acc: 0.9288 - val_loss: 0.3826 - val_acc: 0.8528\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.85225 to 0.85275, saving model to /content/drive/MyDrive/NLP/W-CBOW-POS.h5\n",
            "Epoch 9/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1428 - acc: 0.9471 - val_loss: 0.4099 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.85275\n",
            "Epoch 10/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1059 - acc: 0.9643 - val_loss: 0.4942 - val_acc: 0.8420\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.85275\n",
            "Epoch 11/10000\n",
            "282/282 [==============================] - 5s 16ms/step - loss: 0.0785 - acc: 0.9743 - val_loss: 0.5623 - val_acc: 0.8428\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.85275\n",
            "Epoch 12/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0575 - acc: 0.9830 - val_loss: 0.5679 - val_acc: 0.8292\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.85275\n",
            "Epoch 13/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0823 - acc: 0.9726 - val_loss: 0.6357 - val_acc: 0.8372\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.85275\n",
            "Epoch 14/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0370 - acc: 0.9903 - val_loss: 0.6875 - val_acc: 0.8353\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.85275\n",
            "Epoch 15/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0232 - acc: 0.9947 - val_loss: 0.7026 - val_acc: 0.8322\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.85275\n",
            "Epoch 16/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0247 - acc: 0.9940 - val_loss: 0.7545 - val_acc: 0.8370\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.85275\n",
            "Epoch 17/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.0245 - acc: 0.9942 - val_loss: 0.7522 - val_acc: 0.8378\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.85275\n",
            "Epoch 00017: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6OcgtLY4JUZ",
        "outputId": "485594b1-5cf3-4d69-c556-90ef93cf4572"
      },
      "source": [
        "eval_model(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            " 39/313 [==>...........................] - ETA: 1s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.857700\n",
            "Precision: 0.860447\n",
            "Recall: 0.856519\n",
            "F1 score: 0.858478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KWySv0134rf"
      },
      "source": [
        "**Comment**  \n",
        "The previous results show that each text processing tool impacts differently the classification model perfomance while intragrating it into the training corpus before generating the words embedding. We note that CBOW is litte bit much better than Skip gram in many cases. This can be explained by the fact that Skip gram represents well even rare words or phrases and CBOW is slightly better accuracy for the frequent words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3Z3I8hVD477"
      },
      "source": [
        "# All preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9XdhXZC4LHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f7d8b3-4681-4df8-ec18-9c0511378a80"
      },
      "source": [
        "embedding_matrix = embeddings(path_emb + \"W-Skip-ALL.txt\")\n",
        "model, path = get_model(X_train, y_train, embedding_matrix, path.split(\"/\")[-1].split(\".\")[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "282/282 [==============================] - 38s 17ms/step - loss: 0.6338 - acc: 0.6317 - val_loss: 0.5397 - val_acc: 0.7268\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.72675, saving model to /content/drive/MyDrive/NLP/W-Skip-ALL.h5\n",
            "Epoch 2/10000\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 0.5239 - acc: 0.7421 - val_loss: 0.5425 - val_acc: 0.7450\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.72675 to 0.74500, saving model to /content/drive/MyDrive/NLP/W-Skip-ALL.h5\n",
            "Epoch 3/10000\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 0.4912 - acc: 0.7630 - val_loss: 0.4985 - val_acc: 0.7490\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.74500 to 0.74900, saving model to /content/drive/MyDrive/NLP/W-Skip-ALL.h5\n",
            "Epoch 4/10000\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 0.4655 - acc: 0.7757 - val_loss: 0.4858 - val_acc: 0.7588\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.74900 to 0.75875, saving model to /content/drive/MyDrive/NLP/W-Skip-ALL.h5\n",
            "Epoch 5/10000\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 0.4520 - acc: 0.7878 - val_loss: 0.5533 - val_acc: 0.7415\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.75875\n",
            "Epoch 6/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4346 - acc: 0.8001 - val_loss: 0.4816 - val_acc: 0.7625\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.75875 to 0.76250, saving model to /content/drive/MyDrive/NLP/W-Skip-ALL.h5\n",
            "Epoch 7/10000\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 0.4236 - acc: 0.8019 - val_loss: 0.4569 - val_acc: 0.7807\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.76250 to 0.78075, saving model to /content/drive/MyDrive/NLP/W-Skip-ALL.h5\n",
            "Epoch 8/10000\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 0.4056 - acc: 0.8155 - val_loss: 0.4691 - val_acc: 0.7722\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.78075\n",
            "Epoch 9/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3828 - acc: 0.8301 - val_loss: 0.4951 - val_acc: 0.7807\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.78075\n",
            "Epoch 10/10000\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 0.3635 - acc: 0.8410 - val_loss: 0.4790 - val_acc: 0.7840\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.78075 to 0.78400, saving model to /content/drive/MyDrive/NLP/W-Skip-ALL.h5\n",
            "Epoch 11/10000\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 0.3426 - acc: 0.8519 - val_loss: 0.4869 - val_acc: 0.7887\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.78400 to 0.78875, saving model to /content/drive/MyDrive/NLP/W-Skip-ALL.h5\n",
            "Epoch 12/10000\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 0.3137 - acc: 0.8663 - val_loss: 0.4917 - val_acc: 0.7820\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.78875\n",
            "Epoch 13/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2996 - acc: 0.8727 - val_loss: 0.4793 - val_acc: 0.7738\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.78875\n",
            "Epoch 14/10000\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 0.2699 - acc: 0.8895 - val_loss: 0.5264 - val_acc: 0.7878\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.78875\n",
            "Epoch 15/10000\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 0.2481 - acc: 0.8986 - val_loss: 0.5058 - val_acc: 0.7862\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.78875\n",
            "Epoch 16/10000\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 0.2214 - acc: 0.9129 - val_loss: 0.5636 - val_acc: 0.7845\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.78875\n",
            "Epoch 17/10000\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 0.1966 - acc: 0.9232 - val_loss: 0.5571 - val_acc: 0.7820\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.78875\n",
            "Epoch 00017: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apgeynrGEJZG",
        "outputId": "a346ebe6-4e5f-4106-a4f4-59e21b89b539"
      },
      "source": [
        "eval_model(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            " 39/313 [==>...........................] - ETA: 1s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.798300\n",
            "Precision: 0.793057\n",
            "Recall: 0.811471\n",
            "F1 score: 0.802158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMj2bLCxEKoU",
        "outputId": "a7c924a9-73ba-4ea0-8136-883e64a6f369"
      },
      "source": [
        "embedding_matrix = embeddings(path_emb + \"W-CBOW-ALL.txt\")\n",
        "model, path = get_model(X_train, y_train, embedding_matrix, path.split(\"/\")[-1].split(\".\")[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "282/282 [==============================] - 6s 16ms/step - loss: 0.6012 - acc: 0.6647 - val_loss: 0.5049 - val_acc: 0.7520\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.75200, saving model to /content/drive/MyDrive/NLP/W-CBOW-ALL.h5\n",
            "Epoch 2/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.5007 - acc: 0.7562 - val_loss: 0.4873 - val_acc: 0.7615\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.75200 to 0.76150, saving model to /content/drive/MyDrive/NLP/W-CBOW-ALL.h5\n",
            "Epoch 3/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4696 - acc: 0.7804 - val_loss: 0.5089 - val_acc: 0.7550\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.76150\n",
            "Epoch 4/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4521 - acc: 0.7881 - val_loss: 0.4593 - val_acc: 0.7722\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.76150 to 0.77225, saving model to /content/drive/MyDrive/NLP/W-CBOW-ALL.h5\n",
            "Epoch 5/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4220 - acc: 0.8051 - val_loss: 0.4648 - val_acc: 0.7780\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.77225 to 0.77800, saving model to /content/drive/MyDrive/NLP/W-CBOW-ALL.h5\n",
            "Epoch 6/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.4065 - acc: 0.8145 - val_loss: 0.4550 - val_acc: 0.7788\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.77800 to 0.77875, saving model to /content/drive/MyDrive/NLP/W-CBOW-ALL.h5\n",
            "Epoch 7/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3936 - acc: 0.8244 - val_loss: 0.4728 - val_acc: 0.7840\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.77875 to 0.78400, saving model to /content/drive/MyDrive/NLP/W-CBOW-ALL.h5\n",
            "Epoch 8/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3643 - acc: 0.8370 - val_loss: 0.4734 - val_acc: 0.7790\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.78400\n",
            "Epoch 9/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3338 - acc: 0.8529 - val_loss: 0.4625 - val_acc: 0.7857\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.78400 to 0.78575, saving model to /content/drive/MyDrive/NLP/W-CBOW-ALL.h5\n",
            "Epoch 10/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3211 - acc: 0.8616 - val_loss: 0.4970 - val_acc: 0.7880\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.78575 to 0.78800, saving model to /content/drive/MyDrive/NLP/W-CBOW-ALL.h5\n",
            "Epoch 11/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.2971 - acc: 0.8754 - val_loss: 0.5495 - val_acc: 0.7885\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.78800 to 0.78850, saving model to /content/drive/MyDrive/NLP/W-CBOW-ALL.h5\n",
            "Epoch 12/10000\n",
            "282/282 [==============================] - 5s 16ms/step - loss: 0.2657 - acc: 0.8913 - val_loss: 0.5411 - val_acc: 0.7890\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.78850 to 0.78900, saving model to /content/drive/MyDrive/NLP/W-CBOW-ALL.h5\n",
            "Epoch 13/10000\n",
            "282/282 [==============================] - 4s 16ms/step - loss: 0.2266 - acc: 0.9093 - val_loss: 0.5573 - val_acc: 0.7933\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.78900 to 0.79325, saving model to /content/drive/MyDrive/NLP/W-CBOW-ALL.h5\n",
            "Epoch 14/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1943 - acc: 0.9250 - val_loss: 0.5640 - val_acc: 0.7678\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.79325\n",
            "Epoch 15/10000\n",
            "282/282 [==============================] - 5s 16ms/step - loss: 0.1671 - acc: 0.9365 - val_loss: 0.6075 - val_acc: 0.7770\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.79325\n",
            "Epoch 16/10000\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.1431 - acc: 0.9475 - val_loss: 0.6793 - val_acc: 0.7812\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.79325\n",
            "Epoch 00016: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smQNsas3EMML",
        "outputId": "c8dc05ea-4a6c-4506-9259-7e19f655035c"
      },
      "source": [
        "eval_model(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            " 37/313 [==>...........................] - ETA: 1s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.790600\n",
            "Precision: 0.779465\n",
            "Recall: 0.815043\n",
            "F1 score: 0.796857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "iOgk5_cu3_rC",
        "outputId": "30b94bc5-d3ba-40d8-b81b-a0f640511c64"
      },
      "source": [
        "results = pd.read_csv('F1_score_results.csv',index_col=0)\n",
        "results"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>technique</th>\n",
              "      <th>Score</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stem</td>\n",
              "      <td>0.825123</td>\n",
              "      <td>Skip-gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>stem</td>\n",
              "      <td>0.825753</td>\n",
              "      <td>CBOW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>punc</td>\n",
              "      <td>0.867779</td>\n",
              "      <td>Skip-gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>punc</td>\n",
              "      <td>0.856397</td>\n",
              "      <td>CBOW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>stop</td>\n",
              "      <td>0.843573</td>\n",
              "      <td>Skip-gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>stop</td>\n",
              "      <td>0.837523</td>\n",
              "      <td>CBOW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>post-tag</td>\n",
              "      <td>0.857693</td>\n",
              "      <td>Skip-gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>post-tag</td>\n",
              "      <td>0.858478</td>\n",
              "      <td>CBOW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>All</td>\n",
              "      <td>0.802158</td>\n",
              "      <td>Skip-gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>All</td>\n",
              "      <td>0.796857</td>\n",
              "      <td>CBOW</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  technique     Score      Model\n",
              "0      stem  0.825123  Skip-gram\n",
              "1      stem  0.825753       CBOW\n",
              "2      punc  0.867779  Skip-gram\n",
              "3      punc  0.856397       CBOW\n",
              "4      stop  0.843573  Skip-gram\n",
              "5      stop  0.837523       CBOW\n",
              "6  post-tag  0.857693  Skip-gram\n",
              "7  post-tag  0.858478       CBOW\n",
              "8       All  0.802158  Skip-gram\n",
              "9       All  0.796857       CBOW"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "n2qOW3qe4Y4S",
        "outputId": "64a0c816-337c-4cf1-df26-00d1caef3352"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, ax = plt.subplots(figsize=(15,8))\n",
        "sns.set_context(\"notebook\", font_scale=1.1, rc={\"lines.linewidth\": 2.5})\n",
        "sns.set_style(\"whitegrid\")\n",
        "g = sns.barplot(x=\"technique\", y=\"Score\", hue=\"Model\", data=results)\n",
        "for p in g.patches:\n",
        "    g.annotate(format(p.get_height(), '.3f'), \n",
        "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
        "                   ha = 'center', va = 'center', \n",
        "                   xytext = (0, 9), \n",
        "                   textcoords = 'offset points')\n",
        "plt.title(\"The effect of text processing tools on the classification models performance\",size=18)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'The effect of text processing tools on the classification models performance')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toHNpCpY4eji"
      },
      "source": [
        "The figure above shows the effectiveness of using each processing technique earlier on the training corpus before learning the word embeddings with CBOW and Skip-gram. As we can see, applying all the tools together harm the classification models perfomance. So the choice of the right combination depend on the affective task. Among all the factors, Stemming and Stopword removal are the worse ones which demonstrated previously in the paper. "
      ]
    }
  ]
}
